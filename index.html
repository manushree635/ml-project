<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Social Media and Mental Health Analysis</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            text-align: center;
            color: #2c3e50;
        }

        h1 {
            color: #2c3e50;
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        }

        h2 {
            color: #3498db;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-top: 0;
        }

        h3 {
            color: #2c3e50;
            font-size: 1.2em;
            margin-top: 20px;
        }

        ul {
            margin-left: 20px;
            text-align: left;
            list-style-type: none;
        }

        ul li {
            margin: 10px 0;
            position: relative;
            padding-left: 20px;
        }

        ul li:before {
            content: "•";
            color: #3498db;
            font-weight: bold;
            position: absolute;
            left: 0;
        }

        .section {
            background-color: rgba(255, 255, 255, 0.95);
            padding: 30px;
            margin: 30px auto;
            max-width: 800px;
            border-radius: 15px;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
            text-align: left;
            border: 1px solid rgba(52, 152, 219, 0.2);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .section:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.15);
        }

        a {
            color: #3498db;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        a:hover {
            color: #2980b9;
            text-decoration: underline;
        }

        ol {
            padding-left: 20px;
        }

        ol li {
            margin: 15px 0;
            padding: 10px;
            background: rgba(52, 152, 219, 0.05);
            border-radius: 8px;
        }

        strong {
            color: #2980b9;
        }

        .header-subtitle {
            color: #7f8c8d;
            font-size: 1.2em;
            margin-bottom: 40px;
        }

        @media (max-width: 768px) {
            .section {
                margin: 20px 10px;
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }
        }

        .contribution-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            border-radius: 8px;
            overflow: hidden;
        }
        
        .contribution-table th, .contribution-table td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }
        
        .contribution-table th {
            background-color: #3498db;
            color: white;
            font-weight: 600;
        }
        
        .contribution-table tr:nth-child(even) {
            background-color: #f8f9fa;
        }
        
        .contribution-table tr:hover {
            background-color: #f1f4f6;
        }
    </style>
</head>
<body>

    <h1>Social Media and Mental Health Analysis</h1>
    <h3>CS 7641 Project Proposal - Team 39</h3>

    <div class="section">
        <h2>Problem Definition</h2>
        <h3>Problem:</h3>
        <p>Given that social media platforms have a big impact on our mental health, is there a way to determine a user's mental health status based on factors such as use time?</p>
        
        <h3>Motivation:</h3>
        <ul>
            <li>Social media has made a controversial impact on the lives of many people around the world</li>
            <li>Some users have been able to grow their brand and image</li>
            <li>Others have negative experiences in regards to mental health
                <ul>
                    <li>E.g. Some teens reported bullying using Instagram</li>
                </ul>
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>Literature Review</h2>
        <ul>
            <li><strong>ASSOCIATION BETWEEN SOCIAL MEDIA USE AND DEPRESSION AMONG U.S. YOUNG ADULTS:</strong> 1787 Adults were surveyed about how much they use social media and their level of depression. Findings showed a strong correlation between the two.</li>
            <li><strong>Predicting Depression via Social Media:</strong> Posts of social media users who reported symptoms of depression were collected, and used to predict depression based on posting patterns. Findings showed it may be possible to predict depression based on post content and frequency.</li>
            <li><strong>The Relationship Between Facebook Use and Well-Being:</strong> Activities of Facebook users were used to measure user's psychological well being. Findings showed that communication with people users were close to in real life directly influenced their perceived well being.</li>
        </ul>
    </div>

    <div class="section">
        <h2>Database Description</h2>
        <p><strong>Link:</strong> <a href="https://www.kaggle.com/datasets/emirhanai/social-media-usage-and-emotional-well-being/data" target="_blank">Kaggle Dataset</a></p>
        <p><strong>Description:</strong> This dataset contains a thousand data points that contains information about users' activity on a social media platform like Instagram. Attributes in this dataset include biological info like age and metric collected info like daily usage time. The dataset's main purpose is centered around how users interaction with a social media platform has an effect on their mental health.</p>
    </div>

    <div class="section">
        <h2>Goals & Expected Results</h2>
        <h3>Expected results:</h3>
        <ul>
            <li>We expect to see a negative effect on mood the higher the amount of time a user spends on social media</li>
            <li>If there is a correlation, we expect to be able to predict a user's mood based on that</li>
        </ul>

        <h3>Goals:</h3>
        <ul>
            <li>Classify mood based on social media usage</li>
            <li>Show correlation between social media usage and mood</li>
        </ul>
    </div>

    <div class="section">
        <h2>Data Preprocessing Methods</h2>


        <h3>Data Processing Methods:</h3>
        <p>An important first step was cleaning our dataset to ensure consistency. We:
        </p>
        <ul>
            <li>Fixed misaligned columns</li>
            <li>Removed empty rows</li>
            <li>Removed duplicate entries</li>
            <li>Filled missing values in numerical columns with the mean</li>
            <li>Verified that categorical data matched predefined categories and removed incorrect values
                (for example we removed the entry with "Marie" in the Gender column, where the valid categories are "Male," "Female," and "Non-binary").
            </li>
        </ul>
        <p>
            An example of misaligned columns is provided below. This was the biggest issue in the uncleaned dataset - overall, there were 72 of these problems.
            <div style="text-align: center;">
                <img src="./misaligned columns 1.png" alt="Misaligned columns" style="width: 100%; max-width: 600px; height: auto;">
            </div>
        </p>




        <h3> Dataset Split</h3>
        <p>Our dataset was split into train set and test set with 1000 data points in the train set and 97 data points in the test set.
        We train our model on the train set and test it on the test set.
        </p>


        <h3> Data Visualization </h3>
        <p>Below are some visualizations of our data after implementing the preprocessing steps.</p>


        <div style="text-align: center;">
            <img src="./pie.png" alt="Pie Chart" style="width: 100%; max-width: 600px; height: auto;">
            <img src="./emotions_v_comments.png" alt="Emotions vs Comments" style="width: 100%; max-width: 600px; height: auto;">
            <img src="./emotions_v_likes.png" alt="Emotions vs Likes" style="width: 100%; max-width: 600px; height: auto;">
            <img src="./emotions_v_messages_sent.png" alt="Emotions vs Messages Sent" style="width: 100%; max-width: 600px; height: auto;">
            <img src="./emotions_v_use time.png" alt="Emotions vs Use Time" style="width: 100%; max-width: 600px; height: auto;">
        </div>


        <h3> Feature Reduction Using PCA </h3>
        <p> Given that our dataset had 9 features (not including the y column 'Dominant_Emotion'), we decided to try to use PCA to conduct feature reduction. With feature reduction, we aimed to reduce the size of our training and testing datasets for better performance and reduce chances of overfitting. Steps in this process include: </p>


        <ul>
            <li>Finding the number of principal components (n) to keep, so that they keep at least 95% of the total variance</li>
            <li>Reducing both the training and testing datasets to have n principal components to serve as features and combining it with the y column 'Dominant_Emotion'</li>
            <li>Analyzing how our PCA feature reduction does on a couple of models</li>


        </ul>


        <p>
            Using the graph below, we determined that we could keep 4 Principal Components for every user, effectively reducing our training and testing dataset. This is because we are able to keep at least 95% of the total variance with just 4 Principal Components. After this, we adjusted our training and testing datasets.
            <div style="text-align: center;">
                <img src="./PCA_Graph.png" style="width: 100%; max-width: 600px; height: auto;">
            </div>
           
        </p>
        <p>
            However, our PCA feature reduced datasets aren't working well on well-known ML models. The highest accuracy we got with a model was with k-Nearest Neighbors, but that was 49%. This is really bad and shows the tradeoff between reducing datasets to predicting data points. This point is something to keep in mind when looking at the results of our model with and without PCA.
        </p>


    </div>
   
    <div class="section">
        <h2>Model Selection</h2>
        TODO
    </div>

    <div class="section">
        <h2>Model Overview</h2>
        <h3>Machine Learning Algorithm 1 (Supervised Learning):</h3>
        <ul>
            <li><strong>Bagging Model:</strong> Implemented using <code>BaggingClassifier</code> with <code>DecisionTreeClassifier</code> as the base estimator.</li>
            <li><strong>Technical Definition:</strong> Bagging, or Bootstrap Aggregating, is an ensemble method that improves the stability and accuracy of machine learning algorithms by training multiple models on random subsets of the data and aggregating their predictions.</li>
            <li><strong>Hyperparameters:</strong>
                <ul>
                    <li><code>n_estimators=50</code>: Number of decision trees. This is the number of trees in the forest.</li>
                    <li><code>max_samples=0.5</code>: 50% of training data per estimator. This is the number of samples to draw from the training data.</li>
                    <li><code>max_features=0.5</code>: 50% of features per estimator. This is the number of features to consider when looking for the best split.</li>
                    <li><code>bootstrap=True</code>: Enables bootstrapping. Bootstrap is a technique where the data sample is drawn with replacement.</li>
                    <li><code>oob_score=True</code>: Uses out-of-bag samples for accuracy estimation. Out-of-bag samples are the samples that are not used to train the model.</li>
                </ul>
            </li>
            <li><strong>Best Parameters Found:</strong>
                <ul>
                    <li><code>n_estimators=50</code></li>
                    <li><code>max_samples=0.5</code></li>
                    <li><code>max_features=0.5</code></li>
                </ul>
            </li>
        </ul>

        <h3>Machine Learning Algorithm 2 (Supervised Learning):</h3>
        <ul>
            <li><strong>Random Forest Model:</strong> Implemented using <code>RandomForestClassifier</code> with <code>DecisionTreeClassifier</code> as the base estimator.</li>
            <li><strong>Technical Definition:</strong> Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of their predictions for classification tasks. It introduces randomness by selecting random subsets of features for each split, which helps in reducing overfitting.</li>
            <li><strong>Overview:</strong>
                <ul>
                    <li>Select random number of features and data-points for each decision-tree</li>
                    <li>Each decision tree predicts output</li>
                    <li>Final prediction is based on majority voting in case of classification.</li>
                </ul>
            </li>
            <li><strong>Best Parameters Found:</strong>
                <ul>
                    <li>Num trees: 100</li>
                    <li>Max tree depth: 10</li>
                    <li>Min sample req to split a node: 5</li>
                    <li>Min samples at leaf node: 2</li>
                    <li>Selecting max features for split using 'sqrt'</li>
                </ul>
            </li>
        </ul>

        <h3>Machine Learning Algorithm 3 (Unsupervised Learning):</h3>
        <ul>
            <li><strong>KMeans Clustering:</strong> Implemented using <code>KMeans</code> from the scikit-learn library.</li>
            <li><strong>Technical Definition:</strong> KMeans is an unsupervised learning algorithm that partitions data into K distinct clusters based on feature similarity. It iteratively assigns data points to clusters and updates cluster centroids to minimize the variance within each cluster.</li>
            <li><strong>Objective:</strong> Cluster users based on behavioral factors to explore how these clusterings relate to the separability of their dominant emotions. This could help us identify if meaningful relationships exist in our data.</li>
            <li><strong>Challenge:</strong> Determining the optimal number of clusters is crucial for meaningful analysis.</li>
            <li><strong>Methods to Determine Optimal Clusters:</strong>
                <ul>
                    <li><strong>Elbow Method:</strong> This method involves plotting the explained variation as a function of the number of clusters and picking the elbow of the curve as the number of clusters to use. It helps in identifying the point where adding more clusters does not significantly improve the model.</li>
                    <li><strong>Silhouette Score:</strong> This score measures how similar an object is to its own cluster compared to other clusters. A high silhouette score indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters, thus helping in validating the consistency within clusters of data.</li>
                </ul>
            </li>
            <li><strong>Expected Outcome:</strong> By using KMeans clustering, we aim to uncover patterns in user behavior that correlate with their emotional states, potentially leading to insights into how social media usage impacts mental health.</li>
            <li><strong>Best Parameters:</strong> {'kmeans__init': 'k-means++', 'kmeans__n_clusters': 2, 'kmeans__n_init': 10}</li>
        </ul>

        <h3>Evaluation Metrics</h3>
        <ul>
            <li><strong>Accuracy:</strong> The percentage of correctly classified data points.</li>
            <li><strong>Precision:</strong> The percentage of true positives that were correctly classified.</li>
            <li><strong>Recall:</strong> The percentage of true positives that were correctly classified.</li>
            <li><strong>F1-score:</strong> The harmonic mean of precision and recall.</li>
        </ul>

    </div>


    <div class="section">
        <h2>Model Results</h2>

        <h3>Unsupervised Model</h3>
        TODO

        <h3>Supervised Model</h3>
        TODO

        <h3>Bagging</h3>
        We evaluate our model on the test set and get the following results in the table below for the bagging model with and without pca:


        <table>
            <thead>
                <tr>
                    <th>Metric</th>
                    <th>Bagging Model</th>
                    <th>Bagging Model with PCA</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Accuracy</td>
                    <td>0.96</td>
                    <td>0.43</td>
                </tr>
                <tr>
                    <td>Precision</td>
                    <td>0.95</td>
                    <td>0.42</td>
                </tr>
                <tr>
                    <td>Recall</td>
                    <td>0.96</td>
                    <td>0.43</td>
                </tr>
                <tr>
                    <td>F1-score</td>
                    <td>0.96</td>
                    <td>0.43</td>
                </tr>
            </tbody>
        </table>
       


        <h3>Visualizations</h3>
        <p>We also created a confusion matrix for the bagging model with and without pca to visualize the results.</p>
        <img src="./confusion_matrix_bagging.png" alt="Confusion Matrix of Bagging Model">
        <img src="./confusion_matrix_bagging_without_pca.png" alt="Confusion Matrix of Bagging Model with PCA">


        <h3>Discussion</h3>
        <ul>
            <li>Our model has accuracy of 0.96. This is reasonable because it means that our model is able to correctly classify 96% of the data points which is around 93 samples out of 97.</li>
            <li>We see that the bagging model with pca has a lower accuracy than the bagging model without pca. This is likely because the pca reduces the number of features and removes some important information.</li>
        </ul>


    </div>

    <div class="section">
        <h2>Next Steps</h2>
        <p>This list is a couple of ideas for what our group could possibly do between now and the final presentation:</p>
            <ul>
                <li>Consider using more advanced ensemble methods such as boosting or stacking.</li>
                <li>Explore additional feature selection or transformations that might improve model performance.</li>
                <li>Combine multiple models to create a more robust ensemble, potentially improving accuracy and generalization.</li>
                <li>Research into feature reduction techniques that don't affect our models' accuracy too much, unlike PCA.</li>
            </ul>
    </div>

    <div class="section">
        <h2>References</h2>
        <ol>
            <li>L. yi Lin et al., "Association between Social Media Use and Depression among US Young Adults," Depression and Anxiety, vol. 33, no. 4, pp. 323–331, Jan. 2016, doi: <a href="https://doi.org/10.1002/da.22466" target="_blank">https://doi.org/10.1002/da.22466</a></li>
            <li>M. De Choudhury, M. Gamon, S. Counts, and E. Horvitz, "Predicting Depression via Social Media," Proceedings of the International AAAI Conference on Web and Social Media, vol. 7, no. 1, pp. 128–137, Aug. 2021, doi: <a href="https://doi.org/10.1609/icwsm.v7i1.14432" target="_blank">https://doi.org/10.1609/icwsm.v7i1.14432</a></li>
            <li>M. Burke and R. E. Kraut, "The Relationship Between Facebook Use and Well-Being Depends on Communication Type and Tie Strength," Journal of Computer-Mediated Communication, vol. 21, no. 4, pp. 265–281, Jul. 2016, doi: <a href="https://doi.org/10.1111/jcc4.12162" target="_blank">https://doi.org/10.1111/jcc4.12162</a></li>
        </ol>
    </div>

    <div class="section">
        <h2>Important Links</h2>
        <ul class="links-list">
            <li>
                <strong>GitHub Repository:</strong> 
                <a href="https://github.gatech.edu/aveal6/CS7641_Project" target="_blank">CS7641 Project Repository</a>
            </li>
            <li>
                <strong>Project Timeline:</strong> 
                <a href="https://docs.google.com/spreadsheets/d/14Z7yvJM7WWaoWD7GeCjrhkWzRf-Ky8z5/edit?usp=sharing&ouid=109571213662033046175&rtpof=true&sd=true" target="_blank">Gantt Chart</a>
            </li>
            <li>
                <strong>Video Presentation:</strong> 
                <a href="https://youtu.be/jlIhNwVOmtI" target="_blank">YouTube Video</a>
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>Team Contributions</h2>
        <table class="contribution-table">
            <thead>
                <tr>
                    <th>Team Member</th>
                    <th>Contributions</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Alex</td>
                    <td>
                        <ul>
                            <li>Data Cleaning</li>
                            <li>Update Github Page</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Vineeth</td>
                    <td>
                        <ul>
                            <li>Feature Reduction</li>
                            <li>Update Github Page</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Austin</td>
                    <td>
                        <ul>
                            <li>Data Visualization</li>
                            <li>Model 1 Data Visualization</li>
                            <li>Model 2 Data Visualization</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Manushree</td>
                    <td>
                        <ul>
                            <li>Selection, Implementation, and Analysis of Bagging Model (Model 1)</li>
                            <li>Update Github Page</li>
                        </ul>
                    </td>
                </tr>
                <tr>
                    <td>Tanmay</td>
                    <td>
                        <ul>
                            <li>Selection, Implementation, and Analysis of Random Forest Model (Model 2)</li>
                            <li>Update Github Page</li>
                        </ul>
                    </td>
                </tr>
            </tbody>
        </table>
    </div>

    <div class="section">
        <h2>Project Award Eligibility</h2>
        <p>Our team would like to opt-in to be considered for the "Outstanding Project" award. We understand that the final project website and contributors of winning projects will be featured on the course website.</p>
    </div>

</body>
</html>